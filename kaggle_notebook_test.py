"""
Kaggle Notebookæµ‹è¯•ä»£ç 
ç›´æ¥åœ¨Kaggle Notebookä¸­è¿è¡Œçš„å®Œæ•´æµ‹è¯•ç¤ºä¾‹
"""

# ================================
# Cell 1: ç¯å¢ƒæ£€æŸ¥
# ================================
import os
import sys
import torch
import json
import warnings
warnings.filterwarnings("ignore")

print("ğŸ” Kaggleç¯å¢ƒæ£€æŸ¥")
print(f"Python: {sys.version}")
print(f"PyTorch: {torch.__version__}")
print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
    for i in range(torch.cuda.device_count()):
        print(f"  GPU {i}: {torch.cuda.get_device_name(i)}")

# ================================
# Cell 2: è¿è¡Œç¯å¢ƒè®¾ç½®
# ================================
print("ğŸ”§ è®¾ç½®Kaggleç¯å¢ƒ...")

# å¦‚æœkaggle_setup.pyå­˜åœ¨ï¼Œè¿è¡Œå®ƒ
if os.path.exists('kaggle_setup.py'):
    exec(open('kaggle_setup.py').read())
else:
    print("âš ï¸ æœªæ‰¾åˆ°kaggle_setup.pyï¼Œæ‰‹åŠ¨å®‰è£…ä¾èµ–...")
    
    # æ‰‹åŠ¨å®‰è£…å…³é”®ä¾èµ–
    import subprocess
    packages = [
        "transformers==4.53.2",
        "accelerate>=0.20.0", 
        "soundfile",
        "librosa",
        "liger_kernel",
        "pydub"
    ]
    
    for pkg in packages:
        try:
            subprocess.check_call([sys.executable, "-m", "pip", "install", pkg, "--quiet"])
            print(f"âœ… å®‰è£…: {pkg}")
        except:
            print(f"âŒ å®‰è£…å¤±è´¥: {pkg}")

# ================================
# Cell 3: åˆ›å»ºæµ‹è¯•æ•°æ®
# ================================
print("ğŸ“ åˆ›å»ºæµ‹è¯•æ•°æ®...")

# åŸºäºexamplesçš„æµ‹è¯•æ•°æ®
test_samples = [
    {
        "text": "[S1]Hello! Welcome to MOSS-TTSD-KAGGLE running on Kaggle.[S2]This is incredible! The voice sounds so natural and human-like.[S1]Yes, we're using dual T4 GPUs for acceleration. The quality is amazing!"
    },
    {
        "text": "[S1]ä½ å¥½ï¼æ¬¢è¿ä½¿ç”¨åœ¨Kaggleä¸Šè¿è¡Œçš„MOSS-TTSD-KAGGLEã€‚[S2]å¤ªæ£’äº†ï¼å£°éŸ³å¬èµ·æ¥éå¸¸è‡ªç„¶ï¼Œå°±åƒçœŸäººä¸€æ ·ã€‚[S1]æ˜¯çš„ï¼Œæˆ‘ä»¬ä½¿ç”¨åŒT4 GPUè¿›è¡ŒåŠ é€Ÿï¼Œè´¨é‡éå¸¸æ£’ï¼"
    },
    {
        "text": "[S1]Let me tell you about Context Scaling in AI.[S2]Context Scaling? That sounds fascinating. What exactly does it mean?[S1]It's about helping AI understand complex real-world situations better, not just processing more data."
    }
]

# ä¿å­˜æµ‹è¯•æ•°æ®
with open("kaggle_test_data.jsonl", "w", encoding="utf-8") as f:
    for sample in test_samples:
        f.write(json.dumps(sample, ensure_ascii=False) + "\n")

print(f"âœ… åˆ›å»ºäº† {len(test_samples)} ä¸ªæµ‹è¯•æ ·æœ¬")

# ================================
# Cell 4: è¿è¡Œæ¨ç†æµ‹è¯•
# ================================
print("ğŸµ å¼€å§‹éŸ³é¢‘ç”Ÿæˆæµ‹è¯•...")

# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs("kaggle_test_outputs", exist_ok=True)

# è¿è¡Œæ¨ç†
import subprocess

cmd = [
    sys.executable, "kaggle_inference.py",
    "--jsonl", "kaggle_test_data.jsonl",
    "--output_dir", "kaggle_test_outputs", 
    "--max_samples", "2",  # é™åˆ¶æ ·æœ¬æ•°é‡ä»¥èŠ‚çœæ—¶é—´
    "--use_normalize",
    "--seed", "42"
]

try:
    print("æ‰§è¡Œå‘½ä»¤:", " ".join(cmd))
    result = subprocess.run(cmd, capture_output=True, text=True, timeout=1800)  # 30åˆ†é’Ÿè¶…æ—¶
    
    print("ğŸ“Š æ¨ç†ç»“æœ:")
    if result.returncode == 0:
        print("âœ… æ¨ç†æˆåŠŸå®Œæˆ!")
        # æ˜¾ç¤ºè¾“å‡ºçš„æœ€åå‡ è¡Œ
        output_lines = result.stdout.strip().split('\n')
        for line in output_lines[-10:]:
            if line.strip():
                print(line)
    else:
        print("âŒ æ¨ç†å¤±è´¥")
        print("é”™è¯¯ä¿¡æ¯:")
        print(result.stderr)
        
except subprocess.TimeoutExpired:
    print("â° æ¨ç†è¶…æ—¶ï¼ˆ30åˆ†é’Ÿï¼‰")
except Exception as e:
    print(f"âŒ è¿è¡Œå‡ºé”™: {e}")

# ================================
# Cell 5: æ£€æŸ¥å’Œæ’­æ”¾ç»“æœ
# ================================
print("ğŸ“Š æ£€æŸ¥ç”Ÿæˆç»“æœ...")

output_dir = "kaggle_test_outputs"

# æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
if os.path.exists(output_dir):
    files = os.listdir(output_dir)
    audio_files = [f for f in files if f.endswith('.wav')]
    
    print(f"ğŸµ ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶: {len(audio_files)} ä¸ª")
    
    # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
    for audio_file in audio_files:
        file_path = os.path.join(output_dir, audio_file)
        if os.path.exists(file_path):
            file_size = os.path.getsize(file_path) / 1024  # KB
            print(f"  {audio_file}: {file_size:.1f} KB")
    
    # è¯»å–ç»“æœæŠ¥å‘Š
    results_file = os.path.join(output_dir, "kaggle_results.json")
    if os.path.exists(results_file):
        with open(results_file, "r", encoding="utf-8") as f:
            results = json.load(f)
        
        print("\nğŸ“‹ è¯¦ç»†ç»Ÿè®¡:")
        print(f"  æ€»æ ·æœ¬æ•°: {results.get('total_samples', 'N/A')}")
        print(f"  æˆåŠŸç”Ÿæˆ: {results.get('successful_generations', 'N/A')}")
        print(f"  å¤±è´¥æ•°é‡: {results.get('failed_generations', 'N/A')}")
        
        model_info = results.get('model_info', {})
        print(f"  ä½¿ç”¨è®¾å¤‡: {model_info.get('device', 'N/A')}")
        print(f"  æ³¨æ„åŠ›å®ç°: {model_info.get('attention_implementation', 'N/A')}")
        print(f"  æ–‡æœ¬è§„èŒƒåŒ–: {model_info.get('use_normalize', 'N/A')}")
    
    # åœ¨Notebookä¸­æ’­æ”¾éŸ³é¢‘ï¼ˆå¦‚æœåœ¨Jupyterç¯å¢ƒä¸­ï¼‰
    try:
        from IPython.display import Audio, display
        
        print("\nğŸ§ æ’­æ”¾ç”Ÿæˆçš„éŸ³é¢‘:")
        for i, audio_file in enumerate(audio_files[:3]):  # æœ€å¤šæ’­æ”¾3ä¸ª
            file_path = os.path.join(output_dir, audio_file)
            print(f"æ’­æ”¾éŸ³é¢‘ {i+1}: {audio_file}")
            display(Audio(file_path))
            
    except ImportError:
        print("ğŸ’¡ åœ¨Jupyter Notebookä¸­å¯ä»¥ç›´æ¥æ’­æ”¾éŸ³é¢‘")
        print("ğŸ’¡ è¯·ä¸‹è½½éŸ³é¢‘æ–‡ä»¶åˆ°æœ¬åœ°æ’­æ”¾")

else:
    print("âŒ æœªæ‰¾åˆ°è¾“å‡ºç›®å½•")

# ================================
# Cell 6: æ€§èƒ½ç›‘æ§
# ================================
print("ğŸ“ˆ æ€§èƒ½ç›‘æ§...")

# GPUå†…å­˜ä½¿ç”¨æƒ…å†µ
if torch.cuda.is_available():
    print("GPUå†…å­˜ä½¿ç”¨:")
    for i in range(torch.cuda.device_count()):
        allocated = torch.cuda.memory_allocated(i) / 1024**3
        reserved = torch.cuda.memory_reserved(i) / 1024**3
        print(f"  GPU {i}: {allocated:.2f}GB / {reserved:.2f}GB")

# ç³»ç»Ÿå†…å­˜
try:
    import psutil
    memory = psutil.virtual_memory()
    print(f"ç³»ç»Ÿå†…å­˜: {memory.percent}% ä½¿ç”¨ä¸­")
except ImportError:
    print("æ— æ³•æ£€æŸ¥ç³»ç»Ÿå†…å­˜")

# æ¸…ç†GPUå†…å­˜
torch.cuda.empty_cache()
import gc
gc.collect()
print("ğŸ§¹ GPUå†…å­˜å·²æ¸…ç†")

# ================================
# Cell 7: åˆ›å»ºä¸‹è½½åŒ…
# ================================
print("ğŸ“¦ åˆ›å»ºä¸‹è½½åŒ…...")

import zipfile

def create_results_package():
    """åˆ›å»ºåŒ…å«æ‰€æœ‰ç»“æœçš„å‹ç¼©åŒ…"""
    zip_path = "moss_ttsd_kaggle_test_results.zip"
    
    with zipfile.ZipFile(zip_path, 'w') as zipf:
        # æ·»åŠ éŸ³é¢‘æ–‡ä»¶
        if os.path.exists(output_dir):
            for file in os.listdir(output_dir):
                if file.endswith(('.wav', '.json')):
                    file_path = os.path.join(output_dir, file)
                    zipf.write(file_path, f"results/{file}")
        
        # æ·»åŠ æµ‹è¯•æ•°æ®
        if os.path.exists("kaggle_test_data.jsonl"):
            zipf.write("kaggle_test_data.jsonl", "test_data.jsonl")
    
    return zip_path

# åˆ›å»ºä¸‹è½½åŒ…
if os.path.exists(output_dir):
    zip_file = create_results_package()
    if os.path.exists(zip_file):
        zip_size = os.path.getsize(zip_file) / 1024  # KB
        print(f"âœ… åˆ›å»ºä¸‹è½½åŒ…: {zip_file} ({zip_size:.1f} KB)")
    else:
        print("âŒ åˆ›å»ºä¸‹è½½åŒ…å¤±è´¥")

# ================================
# Cell 8: æµ‹è¯•æ€»ç»“å’Œå»ºè®®
# ================================
print("\n" + "="*50)
print("ğŸ¯ æµ‹è¯•æ€»ç»“")
print("="*50)

# æ£€æŸ¥æµ‹è¯•æ˜¯å¦æˆåŠŸ
success_indicators = [
    os.path.exists(output_dir),
    len([f for f in os.listdir(output_dir) if f.endswith('.wav')]) > 0 if os.path.exists(output_dir) else False,
    os.path.exists(os.path.join(output_dir, "kaggle_results.json")) if os.path.exists(output_dir) else False
]

if all(success_indicators):
    print("ğŸ‰ æµ‹è¯•æˆåŠŸå®Œæˆï¼")
    print("âœ… ç¯å¢ƒè®¾ç½®æ­£ç¡®")
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ") 
    print("âœ… éŸ³é¢‘ç”ŸæˆæˆåŠŸ")
    print("âœ… ç»“æœä¿å­˜æˆåŠŸ")
else:
    print("âš ï¸ æµ‹è¯•éƒ¨åˆ†æˆåŠŸæˆ–å¤±è´¥")
    print("è¯·æ£€æŸ¥ä¸Šé¢çš„é”™è¯¯ä¿¡æ¯")

print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
print("1. æ ¹æ®GPUå†…å­˜è°ƒæ•´--max_sampleså‚æ•°")
print("2. ä½¿ç”¨--use_normalizeæé«˜æ–‡æœ¬å¤„ç†è´¨é‡")
print("3. ç›‘æ§Kaggleçš„9å°æ—¶ä½¿ç”¨é™åˆ¶")
print("4. åŠæ—¶ä¸‹è½½ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶")
print("5. å¯¹äºé•¿æ–‡æœ¬ï¼Œè€ƒè™‘åˆ†æ®µå¤„ç†")

print("\nğŸ”— ä¸‹ä¸€æ­¥:")
print("- ä½¿ç”¨è‡ªå·±çš„æ•°æ®æ›¿æ¢æµ‹è¯•æ•°æ®")
print("- è°ƒæ•´å‚æ•°ä¼˜åŒ–ç”Ÿæˆè´¨é‡")
print("- å°è¯•å£°éŸ³å…‹éš†åŠŸèƒ½ï¼ˆéœ€è¦å‚è€ƒéŸ³é¢‘ï¼‰")
print("- æ‰¹é‡å¤„ç†æ›´å¤šæ ·æœ¬")

print("\nğŸ“ å¦‚æœé‡åˆ°é—®é¢˜:")
print("- æ£€æŸ¥GPUå†…å­˜æ˜¯å¦å……è¶³")
print("- ç¡®è®¤æ‰€æœ‰ä¾èµ–éƒ½å·²å®‰è£…")
print("- æŸ¥çœ‹è¯¦ç»†çš„é”™è¯¯æ—¥å¿—")
print("- å°è¯•å‡å°‘æ‰¹å¤„ç†å¤§å°")

print("="*50)
print("ğŸš€ MOSS-TTSD-KAGGLE æµ‹è¯•å®Œæˆï¼")
print("="*50)